# -*- coding: utf-8 -*-
"""udemy deeplearning course.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ivAYtHB415Mx64u4Ebe0hBC2_Le9u6_1
"""

!pip install tensorflow==2.4.0
import tensorflow as tf
print(tf.__version__)
import numpy as np

tf.__version__

a = tf.constant(9) #creates a tensor
print(a)

b = tf.constant([1,2,3,4])
print(b)

c = tf.constant([[1,2],[3,4]])
print(c)

#numpy array to tensor



array=[]
for i in range(1,5):
  a = int(input("enter the numbers to be converted into tensor:"))
  array.append(a)
numpy_array = np.array(array)
tensor_array = tf.convert_to_tensor(numpy_array)
print(tensor_array)

c = tf.constant([[1,2],[3,4]])

tensor_add1 = tf.add(c,1)
print(tensor_add1)

tensor_sub = tf.subtract(c,1)
tensor_div = tf.divide(c,2)
tensor_mul = tf.multiply(c,3)
print(tensor_sub,tensor_div,tensor_mul)

tensor_matrixmul = tf.matmul(c,tensor_add1)
print(tensor_matrixmul)



#implement activation function



tensor = tf.constant([[3,4],[5,9]],dtype=tf.float64)
tensor

tf.nn.softmax(tensor)

tf.nn.sigmoid(tensor)

tf.nn.relu(tensor)

tf.nn.leaky_relu(tensor)

#import optimizer

optimizer = tf.keras.optimizers.Adam() #import optimizer like this



model = tf.keras.models.Sequential()#sequential object
model.add(tf.keras.Input(shape=(20,)))#dimentions we want to pass in
model.add(tf.keras.layers.Dense(64))#neurons of first layers
model.add(tf.keras.layers.Dense(32))#neurons of secound layer
model.summary()

print(model)

#real example

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

df = pd.read_csv("/content/Churn_Modelling.csv")

df

df.drop(['RowNumber','CustomerId','Surname'],axis=1,inplace=True)

df

df.isnull().sum()

df.info()

df_dict=dict(df.dtypes)

df_dict

df_dict.items()

label_encoder_collection = {}
for col_name,data_type in df_dict.items():
  if data_type == 'object':
    le=LabelEncoder()
    df[col_name] = le.fit_transform(df[col_name])
    label_encoder_collection[col_name] = le

label_encoder_collection

df.info()

x = df.iloc[:,:-1].values.astype(np.float32)
y = df.iloc[:,-1].values.astype(int)

xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.2,random_state = 4)

model = tf.keras.models.Sequential()#sequential object
model.add(tf.keras.Input(shape=(10,)))#dimentions we want to pass in
model.add(tf.keras.layers.Dense(32))#neurons of first layers
model.add(tf.keras.layers.Dense(32))#neurons of secound layer
model.add(tf.keras.layers.Dense(1, activation='sigmoid'))
model.summary()

optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) #import optimizer like this
model.compile(optimizer,loss='binary_crossentropy',metrics=["accuracy"])

history = model.fit(xtrain,ytrain,validation_data=(xtest,ytest),epochs=20)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('accuract=y of model')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.show()

predictions = np.round(model.predict(xtest))

from sklearn.metrics import accuracy_score , confusion_matrix
accuracy_score(ytest,predictions)

confusion_matrix(ytest,predictions)

from sklearn.utils.class_weight import compute_class_weight
class_weights = compute_class_weight(class_weight = 'balanced',classes=np.unique(ytrain),y=ytrain)

model_class_weights={}
for e,weight in enumerate(class_weights):
  model_class_weights[e]=weight

model_class_weights

import keras
from keras.layers.normalization import BatchNormalization

model = tf.keras.models.Sequential()
model.add(tf.keras.Input(shape=(10,)))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Dense(128 , activation='relu'))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Dense(64,activation='relu'))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Dense(32,activation='relu'))
model.add(tf.keras.layers.Dense(1, activation='sigmoid'))
model.summary()

optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) #import optimizer like this
model.compile(optimizer,loss='binary_crossentropy',metrics=["accuracy"])

history = model.fit(xtrain,ytrain,validation_data=(xtest,ytest),epochs=20)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('accuract=y of model')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.show()

predictions = np.round(model.predict(xtest))

from sklearn.metrics import accuracy_score , confusion_matrix
accuracy_score(ytest,predictions)

confusion_matrix(ytest,predictions)