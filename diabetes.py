# -*- coding: utf-8 -*-
"""diabetes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Uvgw8lQflCudbp0da0Ew2ZQcXgygyMOU

#importing libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
from sklearn.linear_model import LogisticRegression
import pickle
from sklearn.neighbors import KNeighborsClassifier

"""# data description and eda

"""

diaDF = pd.read_csv('/content/diabetes.csv')



diaDF

diaDF.info()

diaDF.describe()

diaDF.head(20)

diaDF['BloodPressure']

diaDF.boxplot(column=['BloodPressure'])

diaDF=diaDF[diaDF['BloodPressure']>30]

diaDF=diaDF[diaDF['BloodPressure']<110]

diaDF.head(20)

diaDF.boxplot(column=['SkinThickness'])

diaDF['SkinThickness'].value_counts()

mean_thickness = diaDF['SkinThickness'].dropna().mean()

mean_thickness

diaDF['SkinThickness']=diaDF.SkinThickness.mask(diaDF.SkinThickness == 0,mean_thickness)

diaDF.head(20)

mean_insulin = diaDF['Insulin'].dropna().mean()

mean_insulin

diaDF['Insulin']=diaDF.Insulin.mask(diaDF.Insulin == 0,mean_insulin)

diaDF.head(20)

diaDF.boxplot(column=['Insulin'])

diaDF.boxplot(column=['Pregnancies'])

diaDF['Pregnancies'].value_counts()

"""#datavisualization

"""

corr = diaDF.corr()
print(corr)
sns.heatmap(corr, 
         xticklabels=corr.columns, 
         yticklabels=corr.columns)

sns.set(style="darkgrid")
ax = sns.countplot(x="Outcome", data=diaDF)

sns.set(style="darkgrid")
ax = sns.barplot(y="Insulin",x="Outcome", data=diaDF)

sns.kdeplot(x = 'Insulin' , data = diaDF , color = 'black')

sns.kdeplot(x = 'BMI' , data = diaDF , color = 'black')

diaDF.columns

x = diaDF[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',
       'BMI', 'DiabetesPedigreeFunction', 'Age']].values
y = diaDF[['Outcome']].values

"""#using logistic regression

"""

diaDF['Outcome'].value_counts(
)

x_u = diaDF[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',
       'BMI', 'DiabetesPedigreeFunction', 'Age']]
y_u = diaDF[['Outcome']]

from imblearn.under_sampling import RandomUnderSampler
rus=RandomUnderSampler()

x_u,y_u=rus.fit_resample(x_u,y_u)

x_u.shape,y_u.shape

from sklearn.model_selection import train_test_split
xu_train,xu_test,yu_train,yu_test = train_test_split(x_u,y_u)

from sklearn.linear_model import LogisticRegression
lr_u=LogisticRegression()
lr_u.fit(xu_train,yu_train)

yu_pred=lr_u.predict(xu_test)
yu_pred

from sklearn.metrics import accuracy_score
accuracy_score(yu_test,yu_pred)

filename = 'lr_model2.sav'
pickle.dump(lr, open(filename, 'wb'))
loaded_model = pickle.load(open(filename, 'rb'))
result = loaded_model.score(xu_test, yu_test)
print(result)

"""#xgboost

"""

pip install xgboost

import xgboost as xgb

train = xgb.DMatrix(xu_train , label = yu_train)
test = xgb.DMatrix(xu_test , label = yu_test)

params =  {
    'max_depth':5,
    'eta':0.5,
    'objective':'multi:softmax',
    'num_class':5}
epochs = 20

model = xgb.train(params,train,epochs)

predicta = model.predict(test)

from sklearn.metrics import accuracy_score
accuracy_score(yu_test,predicta)