# -*- coding: utf-8 -*-
"""Pandas_Class-200520-125601.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18KWgs6lVqMf-RA6b7RZmPwVIU1f0yjVh

## How do I read a tabular data file into pandas?
"""

tsv - \t
csv  - ,
txt   - \t,',',| 

xlsx

import pandas as pd
# read a dataset of Chipotle orders directly from a URL and store the results in a DataFrame
orders = pd.read_table('http://bit.ly/chiporders',sep='\t')

# examine the first 5 rows
orders.head()

"""Documentation for [**`read_table`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_table.html)"""

# read a dataset of movie reviewers (modifying the default parameter values for read_table)
user_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']
user = pd.read_csv(r"C:\Users\Guhan\Documents\Verzeo\user.txt",sep='|', header=None, names=user_cols)

pd.read_excel('ufo.xlsx',sheet_name='ufo') #  shift + tab to see the fuction details

# examine the first 5 rows
user.head()

user.tail()

"""## How do I select a pandas Series from a DataFrame?"""

# read a dataset of UFO reports into a DataFrame
import pandas as pd
ufo = pd.read_table('ufo.csv', sep=',')

# read_csv is equivalent to read_table, except it assumes a comma separator
ufo = pd.read_csv('ufo.csv')

# examine the first 5 rows
ufo.head()

# select the 'City' Series using bracket notation
ufo['City']

# or equivalently, use dot notation
ufo.State #2

"""<!-- **Bracket notation** will always work, whereas **dot notation** has limitations: -->

- Dot notation doesn't work if there are **spaces** in the Series name
- Dot notation doesn't work if the Series has the same name as a **DataFrame method or attribute** (like 'head' or 'shape')
- Dot notation can't be used to define the name of a **new Series** (see below)
"""

# create a new 'Location' Series (must use bracket notation to define the Series name)
ufo['Location'] = ufo.City + ', ' + ufo.State
ufo.head()

ufo.shape

"""## Why do some pandas commands end with parentheses (and others don't)?"""

# read a dataset of top-rated IMDb movies into a DataFrame
import pandas as pd
movies = pd.read_csv('http://bit.ly/imdbratings')

"""**Methods** end with parentheses, while **attributes** don't:"""

# example method: show the first 5 rows
movies.head()

movies.columns

movies.info()

movies.genre.nunique()

movies.genre.unique()

# example method: calculate summary statistics
movies.describe()

movies.describe(include='all')

# use an optional parameter to the describe method to summarize only 'object' columns
movies.describe(include='object')

movies.info()

# example attribute: number of rows and columns
movies.shape

# example attribute: data type of each column
movies.dtypes

"""Documentation for [**`describe`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)

## 5. How do I rename columns in a pandas DataFrame?
"""

ufo = pd.read_csv('ufo.csv')

# examine the column names
ufo.columns

# rename two of the columns by using the 'rename' method
# ufo.columns = ufo.rename(columns={'Colors Reported':'Colors_Reported', 'Shape Reported':'Shape_Reported'}) # do not use
ufo.rename(columns={'Colors Reported':'Colors_Reported', 'Shape Reported':'Shape_Reported'}, inplace=True)
ufo.columns

"""Documentation for [**`rename`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rename.html)"""

ufo.columns

# replace all of the column names by overwriting the 'columns' attribute
ufo_cols = ['city', 'colors reported', 'shape reported', 'state', 'time']
ufo.columns = ufo_cols
ufo.columns

# replace the column names during the file reading process by using the 'names' parameter
ufo = pd.read_csv('ufo.csv', header=0, names=ufo_cols)
ufo.columns

"""Documentation for [**`read_csv`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)"""

# replace all spaces with underscores in the column names by using the 'str.replace' method
ufo.columns = ufo.columns.str.replace(' ', '_')
ufo.columns

"""Documentation for [**`str.replace`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.replace.html)

##  How do I remove columns from a pandas DataFrame?
"""

# read a dataset of UFO reports into a DataFrame
ufo = pd.read_csv('ufo.csv')
ufo.head()

# remove a single column (axis=1 refers to columns)
ufo.drop('Colors Reported', axis=1, inplace=True)
ufo.head()

"""Documentation for [**`drop`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html)"""

# remove multiple columns at once
ufo.drop(['City', 'State'], axis=1, inplace=True)
ufo.head()

ufo.head(10)

ufo.reset_index(inplace=True)

ufo.head()

# remove multiple rows at once (axis=0 refers to rows)
ufo.drop([2,9], axis=0, inplace=True)
# ufo.reset_index()

"""## How do I sort a pandas DataFrame or a Series?"""

# read a dataset of top-rated IMDb movies into a DataFrame
# import pandas as pd
movies = pd.read_csv('http://bit.ly/imdbratings')
movies.head()

"""**Note:** None of the sorting methods below affect the underlying data. (In other words, the sorting is temporary)."""

# sort the 'title' Series in ascending order (returns a Series)
movies.title.sort_values().head()

# sort in descending order instead
movies.title.sort_values(ascending=False).head()

"""Documentation for [**`sort_values`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.sort_values.html) for a **Series**. (Prior to version 0.17, use [**`order`**](http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.Series.order.html) instead.)"""

# sort the entire DataFrame by the 'title' Series (returns a DataFrame)
movies.sort_values('star_rating').head()

# sort in descending order instead
movies.sort_values('title', ascending=False).head()

"""Documentation for [**`sort_values`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html) for a **DataFrame**. (Prior to version 0.17, use [**`sort`**](http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.sort.html) instead.)"""

# sort the DataFrame first by 'content_rating', then by 'duration'
movies.sort_values(['star_rating', 'duration','content_rating'],ascending=[False,True,True]).head(10)

"""
## How do I filter rows of a pandas DataFrame by column value?"""

# read a dataset of top-rated IMDb movies into a DataFrame
movies = pd.read_csv('http://bit.ly/imdbratings')
movies.head()

# examine the number of rows and columns
movies.shape

"""**Goal:** Filter the DataFrame rows to only show movies with a 'duration' of at least 200 minutes."""

movies.duration

movies.duration >= 200

movies[movies.duration >= 200]['title']

# simplify the steps above: no need to write a for loop to create 'is_long' since pandas will broadcast the comparison
is_long = movies.duration >= 200
movies[is_long]

# or equivalently, write it in one line (no need to create the 'is_long' object)
movies[movies.duration >= 200]

# select the 'genre' Series from the filtered DataFrame
movies[movies.duration >= 200].genre

"""Documentation for [**`loc`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html)

## How do I apply multiple filter criteria to a pandas DataFrame?
"""

# read a dataset of top-rated IMDb movies into a DataFrame
import pandas as pd
movies = pd.read_csv('http://bit.ly/imdbratings')
movies.head()

# filter the DataFrame to only show movies with a 'duration' of at least 200 minutes
movies[movies.duration >= 200]

"""Understanding **logical operators:**

- **`and`**: True only if **both sides** of the operator are True
- **`or`**: True if **either side** of the operator is True

Rules for specifying **multiple filter criteria** in pandas:

- use **`&`** instead of **`and`**
- use **`|`** instead of **`or`**
- add **parentheses** around each condition to specify evaluation order

**Goal:** Further filter the DataFrame of long movies (duration >= 200) to only show movies which also have a 'genre' of 'Drama'
"""

# use the '&' operator to specify that both conditions are required
movies[(movies.duration >=200) & (movies.genre == 'Drama')]

# using the '|' operator would have shown movies that are either long or dramas (or both)
movies[(movies.duration >=200) | (movies.genre == 'Drama')].head()

"""**Goal:** Filter the original DataFrame to show movies with a 'genre' of 'Crime' or 'Drama' or 'Action'"""

# use the '|' operator to specify that a row can match any of the three criteria
movies[(movies.genre == 'Crime') | (movies.genre == 'Drama') | (movies.genre == 'Action')].head(10)

# or equivalently, use the 'isin' method
movies[movies.genre.isin(['Crime', 'Drama', 'Action'])].head(10)
# movies[movies.genre.isin(['Crime','Drame','Action'])].title

"""Documentation for [**`isin`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.isin.html)

### When reading from a file, how do I read in only a subset of the columns?
"""

# read a dataset of UFO reports into a DataFrame, and check the columns
import pandas as pd
ufo = pd.read_csv('ufo.csv')
ufo.columns

# specify which columns to include by name
ufo = pd.read_csv('ufo.csv', usecols=['City', 'State'])
print(ufo.columns)
# or equivalently, specify columns by position
ufo = pd.read_csv('ufo.csv', usecols=[0, 4])
ufo.columns

ufo.head()

"""**Question:** When reading from a file, how do I read in only a subset of the rows?"""

# specify how many rows to read
ufo = pd.read_csv('ufo.csv', nrows=3)
ufo

"""Documentation for [**`read_csv`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)

Documentation for [**`select_dtypes`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.select_dtypes.html)

## How do I use string methods in pandas?
"""

# read a dataset of Chipotle orders into a DataFrame
orders = pd.read_table('http://bit.ly/chiporders')
orders.head()

# normal way to access string methods in Python
'hello'.upper()

# string methods for pandas Series are accessed via 'str'
orders.item_name.str.upper().head()

# string method 'contains' checks for a substring and returns a boolean Series
orders.item_name.str.contains('Chicken').head()

# use the boolean Series to filter the DataFrame
orders[orders.item_name.str.contains('Chicken')].head()

# string methods can be chained together
orders.choice_description.str.replace('[', '').str.replace(']', '').str.replace(',','').str.lower().head()

# many pandas string methods support regular expressions (regex)
orders.choice_description.str.replace('[\[\]\(\)]', '').head()

"""[String handling section](http://pandas.pydata.org/pandas-docs/stable/api.html#string-handling) of the pandas API reference

## How do I change the data type of a pandas Series?
"""

# read a dataset of alcohol consumption into a DataFrame
import pandas as pd
drinks = pd.read_csv('http://bit.ly/drinksbycountry')
drinks.head()

# examine the data type of each Series
drinks.dtypes

# change the data type of an existing Series
drinks['beer_servings'] = drinks.beer_servings.astype(float)
drinks.dtypes

"""Documentation for [**`astype`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.astype.html)"""

# alternatively, change the data type of a Series while reading in a file
drinks = pd.read_csv('http://bit.ly/drinksbycountry', dtype={'spirit_servings':float})
drinks.dtypes

# read a dataset of Chipotle orders into a DataFrame
orders = pd.read_table('http://bit.ly/chiporders')
orders.head()

# examine the data type of each Series
orders.dtypes

# convert a string to a number in order to do math
orders.item_price.str.replace('$', '').astype(float).mean()

# string method 'contains' checks for a substring and returns a boolean Series
orders.item_name.str.contains('Chicken').head()

# convert a boolean Series to an integer (False = 0, True = 1)
orders.item_name.str.contains('Chicken').astype(int).head()

"""## When should I use a "groupby" in pandas?"""

# read a dataset of alcohol consumption into a DataFrame
import pandas as pd
drinks = pd.read_csv('http://bit.ly/drinksbycountry')
drinks.head()

drinks.describe()

# calculate the mean beer servings across the entire dataset
drinks.beer_servings.mean()

# calculate the mean beer servings just for countries in Africa
drinks[drinks.continent=='Asia'].beer_servings.mean()

drinks.continent.unique()

# calculate the mean beer servings for each continent
drinks.groupby('continent').describe()['beer_servings']

"""Documentation for [**`groupby`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html)"""

# other aggregation functions (such as 'max') can also be used with groupby
drinks.groupby('continent').beer_servings.max()

# multiple aggregation functions can be applied simultaneously
import numpy as np

drinks.groupby('continent').agg(['count', 'mean', 'min', 'max','sum','median',np.percentile(25,25)])['beer_servings'].count

"""Documentation for [**`agg`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.DataFrameGroupBy.agg.html)"""

# specifying a column to which the aggregation function should be applied is not required
drinks.groupby('continent').mean()

drinks.describe()

# Commented out IPython magic to ensure Python compatibility.
# allow plots to appear in the notebook
import matplotlib.pyplot as plt
# %matplotlib inline

# side-by-side bar plot of the DataFrame directly above
drinks.groupby('continent').beer_servings.mean().plot(kind='barh')

"""Documentation for [**`plot`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html)"""

# count how many times each value in the Series occurs
movies.genre.value_counts()

"""Documentation for [**`value_counts`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.value_counts.html)"""

movies.head(10)

# display percentages instead of raw counts
movies.genre.value_counts(normalize=True)

# 'value_counts' (like many pandas methods) outputs a Series
type(movies.genre.value_counts())

"""Documentation for [**`unique`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.unique.html) and [**`nunique`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.nunique.html)"""

import pandas as pd
movies = pd.read_csv('http://bit.ly/imdbratings')
movies.head()

print(movies.content_rating.nunique())
movies.genre.nunique()

genre - 16 
content_rating -12
12*16 = 192

"""https://pbpython.com/pandas-crosstab.html

https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html

https://nikgrozev.com/2015/07/01/reshaping-in-pandas-pivot-pivot-table-stack-and-unstack-explained-with-pictures/
"""

import numpy as np
np.eye(3,3)
np.identity(3)

# compute a +cross-tabulation of two Series
pd.crosstab(movies.genre, movies.content_rating,margins=True)
# genre.action, content_Rating.approved - 3

"""Documentation for [**`crosstab`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.crosstab.html)"""

# 'value_counts' is primarily useful for categorical data, not numerical data
movies.duration.value_counts

# histogram of the 'duration' Series (shows the distribution of a numerical variable)
movies.duration.plot(kind='hist')

# bar plot of the 'value_counts' for the 'genre' Series
movies.genre.value_counts().plot(kind='bar')

"""Documentation for [**`plot`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.plot.html)

## How do I handle missing values in pandas?
"""

# read a dataset of UFO reports into a DataFrame
import pandas as pd
ufo = pd.read_csv('http://bit.ly/uforeports')
ufo.tail()

"""**What does "NaN" mean?**

- "NaN" is not a string, rather it's a special value: **`numpy.nan`**.
- It stands for "Not a Number" and indicates a **missing value**.
- **`read_csv`** detects missing values (by default) when reading the file, and replaces them with this special value.

Documentation for [**`read_csv`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)
"""

# 'isnull' returns a DataFrame of booleans (True if missing, False if not missing)
ufo.isnull().tail()

# 'nonnull' returns the opposite of 'isnull' (True if not missing, False if missing)
ufo.notnull().tail()

"""Documentation for [**`isnull`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.isnull.html) and [**`notnull`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.notnull.html)"""

# count the number of missing values in each Series
ufo.isnull().sum()

"""This calculation works because:

1. The **`sum`** method for a DataFrame operates on **`axis=0`** by default (and thus produces column sums).
2. In order to add boolean values, pandas converts **`True`** to **1** and **`False`** to **0**.
"""

# use the 'isnull' Series method to filter the DataFrame rows
ufo[ufo.City.isnull()].head()

"""**How to handle missing values** depends on the dataset as well as the nature of your analysis. Here are some options:"""

# examine the number of rows and columns
ufo.shape

# if 'any' values are missing in a row, then drop that row
ufo.dropna(how='any').shape

"""Documentation for [**`dropna`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html)"""

# 'inplace' parameter for 'dropna' is False by default, thus rows were only dropped temporarily
ufo.shape

# if 'all' values are missing in a row, then drop that row (none are dropped in this case)
ufo.dropna(how='all').shape

# if 'any' values are missing in a row (considering only 'City' and 'Shape Reported'), then drop that row
ufo.dropna(subset=['City', 'Shape Reported'], how='any').shape

# if 'all' values are missing in a row (considering only 'City' and 'Shape Reported'), then drop that row
ufo.dropna(subset=['City', 'Shape Reported'], how='all').shape

# 'value_counts' does not include missing values by default
ufo['Shape Reported'].value_counts()

# explicitly include missing values
ufo['Shape Reported'].value_counts(dropna=False)

"""Documentation for [**`value_counts`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.value_counts.html)"""

# fill in missing values with a specified value
ufo['Shape Reported'].fillna(value='VARIOUS', inplace=True)
# ufo['Shape Reported'].isnull().sum()

"""Documentation for [**`fillna`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html)"""

# confirm that the missing values were filled in
ufo['Shape Reported'].value_counts().head()

"""[Working with missing data in pandas](http://pandas.pydata.org/pandas-docs/stable/missing_data.html)"""

drinks = pd.read_csv('http://bit.ly/drinksbycountry')
drinks.head()

# 'country' is now the index
# drinks.set_index('country',inplace=True)
drinks.head()

# 'country' is no longer a column
drinks.columns

# 'country' data is no longer part of the DataFrame contents
drinks.shape

# country name can now be used for selection
drinks.loc['Brazil', 'beer_servings']

# index name is optional
drinks.index.name = None
drinks.head()

# restore the index name, and move the index back to a column
drinks.index.name = 'country'
drinks.reset_index(inplace=True)
drinks.head()

"""Documentation for [**`reset_index`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reset_index.html)

## How do I select multiple rows and columns from a pandas DataFrame?
"""

# read a dataset of UFO reports into a DataFrame
ufo = pd.read_csv('http://bit.ly/uforeports')
ufo.head(3)

# loc  - [index/bool,'column names']
# iloc - [index/bool,index position]

"""The [**`loc`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html) method is used to select rows and columns by **label**. You can pass it:

- A single label
- A list of labels
- A slice of labels
- A boolean Series
- A colon (which indicates "all labels")
"""

# row 0, all columns
ufo.loc[1, :]

# rows 0 and 1 and 2, all columns
ufo.loc[[0, 1, 2], :]

# rows 0 through 2 (inclusive), all columns
ufo.loc[0:2, :]

# this implies "all columns", but explicitly stating "all columns" is better
ufo.loc[0:2]

# rows 0 through 2 (inclusive), column 'City'
ufo.loc[0:10, 'City']

# rows 0 through 2 (inclusive), columns 'City' and 'State'
ufo.loc[0:2, ['City', 'State']]

# accomplish the same thing using double brackets - but using 'loc' is preferred since it's more explicit
ufo[['City', 'State']].head(3)

# rows 0 through 2 (inclusive), columns 'City' through 'State' (inclusive)
ufo.loc[0:2, 'City':'State']

# accomplish the same thing using 'head' and 'drop'
ufo.head(3).drop('Time', axis=1)

# rows in which the 'City' is 'Oakland', column 'State'
ufo.loc[ufo.City=='Oakland', 'State']

# accomplish the same thing using "chained indexing" - but using 'loc' is preferred since chained indexing can cause problems
ufo[ufo.City=='Oakland'].State

"""The [**`iloc`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iloc.html) method is used to select rows and columns by **integer position**. You can pass it:

- A single integer position
- A list of integer positions
- A slice of integer positions
- A colon (which indicates "all integer positions")
"""

ufo.head()

# rows in positions 0 and 1, columns in positions 0 and 3
ufo.iloc[[0, 1], [0, 3]]

# rows in positions 0 through 2 (exclusive), columns in positions 0 through 4 (exclusive)
ufo.iloc[0:2, 0:4]

# rows in positions 0 through 2 (exclusive), all columns
ufo.iloc[0:2, :]

# accomplish the same thing - but using 'iloc' is preferred since it's more explicit
ufo[0:2]

# read a dataset of alcohol consumption into a DataFrame and set 'country' as the index
import pandas as pd
drinks = pd.read_csv('http://bit.ly/drinksbycountry', index_col='country')
drinks.head()

# use the 'category' data type (new in pandas 0.15) to store the 'continent' strings as integers
# drinks.reset_index(inplace=True)
drinks['continent'] = drinks.continent.astype('category')
drinks.dtypes

# 'continent' Series appears to be unchanged
drinks.continent.head()

7 - africa - 0

# strings are now encoded (0 means 'Africa', 1 means 'Asia', 2 means 'Europe', etc.)
drinks.continent.cat.codes.head()

# memory usage has been drastically reduced
drinks.memory_usage(deep=True)

# repeat this process for the 'country' Series
drinks.index = drinks.index.astype('category')
drinks.memory_usage(deep=True)

# memory usage increased because we created 193 categories
drinks.index.astype('category').categories

"""The **category** data type should only be used with a string Series that has a **small number of possible values**."""

goodl

# create a small DataFrame from a dictionary
import pandas as pd
df = pd.DataFrame({'ID':[100, 101, 102, 103], 'quality':['good', 'very good', 'good', 'excellent']})
df



# sort the DataFrame by the 'quality' Series (alphabetical order)
df.sort_values('quality')

# define a logical ordering for the categories
from pandas.api.types import CategoricalDtype
cat_type = CategoricalDtype(categories=['good', 'very good', 'excellent'], ordered=True)
df['quality'] = df.quality.astype(cat_type)
df.quality

# sort the DataFrame by the 'quality' Series (logical order)
df.sort_values('quality')

# comparison operators work with ordered categories
df.loc[df.quality > 'good', :]

"""[Overview of categorical data in pandas](http://pandas.pydata.org/pandas-docs/stable/categorical.html)

[API reference for categorical methods](http://pandas.pydata.org/pandas-docs/stable/api.html#categorical)

## How do I create dummy variables in pandas?
"""

# read the training dataset from Kaggle's Titanic competition
import pandas as pd
train = pd.read_csv('http://bit.ly/kaggletrain')
train.head()

# create the 'Sex_male' dummy variable using the 'map' method
train['Sex_male'] = train.Sex.map({'female':0, 'male':1})
train.head()

"""Documentation for [**`map`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.map.html)"""

# alternative: use 'get_dummies' to create one column for every possible value
pd.get_dummies(train.Sex,prefix = 'Sex',prefix_sep='_',drop_first=True).head()

"""Generally speaking:

- If you have **"K" possible values** for a categorical feature, you only need **"K-1" dummy variables** to capture all of the information about that feature.
- One convention is to **drop the first dummy variable**, which defines that level as the "baseline".
"""

# drop the first dummy variable ('female') using the 'iloc' method
pd.get_dummies(train.Sex).iloc[:, 1:].head()

# add a prefix to identify the source of the dummy variables
pd.get_dummies(train.Sex, prefix='Sex').iloc[:, 1:].head()

train.Embarked.unique()

train.Embarked.head(10)

# use 'get_dummies' with a feature that has 3 possible values
pd.get_dummies(train.Embarked, prefix='Embarked').head(10)

# drop the first dummy variable ('C')
pd.get_dummies(train.Embarked, prefix='Embarked').iloc[:, 1:].head(10)

"""How to translate these values back to the original 'Embarked' value:

- **0, 0** means **C**
- **1, 0** means **Q**
- **0, 1** means **S**
"""

# save the DataFrame of dummy variables and concatenate them to the original DataFrame
embarked_dummies = pd.get_dummies(train.Embarked, prefix='Embarked').iloc[:, 1:]
train = pd.concat([train, embarked_dummies], axis=1)
train.head()

"""Documentation for [**`concat`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html)"""

# reset the DataFrame
train = pd.read_csv('http://bit.ly/kaggletrain')
train.head()

# pass the DataFrame to 'get_dummies' and specify which columns to dummy (it drops the original columns)
pd.get_dummies(train, columns=['Sex', 'Embarked']).head()

# 0
# 1
# 2

#
embarked
s=0
c=1
q=2

embr

from sklearn.preprocessing import preprocessing
le = LabelEncoder()
le = preprocessing.LabelEncoder()
train['Embarked']= le.fit_transform(train['Embarked'])
# movies

# use the 'drop_first' parameter (new in pandas 0.18) to drop the first dummy variable for each feature
pd.get_dummies(train, columns=['Sex', 'Embarked'], drop_first=True).head()

"""Documentation for [**`get_dummies`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)

## How do I work with dates and times in pandas?

https://towardsdatascience.com/basic-time-series-manipulation-with-pandas-4432afee64ea

https://www.geeksforgeeks.org/python-working-with-date-and-time-using-pandas/
"""

# read a dataset of UFO reports into a DataFrame
ufo = pd.read_csv('http://bit.ly/uforeports')
ufo.head()

# 'Time' is currently stored as a string
ufo.dtypes

# hour could be accessed using string slicing, but this approach breaks too easily
ufo.Time.str.slice(-5, -3).astype(int).head()

# convert 'Time' to datetime format
ufo['Time'] = pd.to_datetime(ufo.Time)
ufo.head()

ufo.dtypes

"""Documentation for [**`to_datetime`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.to_datetime.html)"""

# convenient Series attributes are now available
ufo.Time.dt.hour.head()

# ufo.Time.dt.we

ufo.Time.dt.dayofyear.head()

"""API reference for [datetime properties and methods](http://pandas.pydata.org/pandas-docs/stable/api.html#datetimelike-properties)"""

# convert a single string to datetime format (outputs a timestamp object)
ts = pd.to_datetime('1/1/1999')
ts

# compare a datetime Series with a timestamp
ufo.loc[ufo.Time >= ts, :].head()

# perform mathematical operations with timestamps (outputs a timedelta object)
ufo.Time.max() - ufo.Time.min()

# timedelta objects also have attributes you can access
(ufo.Time.max() - ufo.Time.min()).days

# Commented out IPython magic to ensure Python compatibility.
# allow plots to appear in the notebook
# %matplotlib inline

# count the number of UFO reports per year
ufo['Year'] = ufo.Time.dt.year
ufo.Year.value_counts().sort_index().head()

# plot the number of UFO reports per year (line plot is the default)
ufo.Year.value_counts().sort_index().plot()

"""## How do I find and remove duplicate rows in pandas?"""

# read a dataset of movie reviewers into a DataFrame
user_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']
users = pd.read_table('http://bit.ly/movieusers', sep='|', header=None, names=user_cols, index_col='user_id')
users.head()

users.shape

# detect duplicate zip codes: True if an item is identical to a previous item
users.zip_code.duplicated().tail()

# count the duplicate items (True becomes 1, False becomes 0)
users.zip_code.duplicated().sum()

# detect duplicate DataFrame rows: True if an entire row is identical to a previous row
users.duplicated().tail()

# count the duplicate rows
users.duplicated().sum()

"""Logic for [**`duplicated`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.duplicated.html):

- **`keep='first'`** (default): Mark duplicates as True except for the first occurrence.
- **`keep='last'`**: Mark duplicates as True except for the last occurrence.
- **`keep=False`**: Mark all duplicates as True.
"""

# examine the duplicate rows (ignoring the first occurrence)
users.loc[users.duplicated(keep='first'), :]

# examine the duplicate rows (ignoring the last occurrence)
users.loc[users.duplicated(keep='last'), :]

# examine the duplicate rows (including all duplicates)
users.loc[users.duplicated(keep=False), :]

# drop the duplicate rows (inplace=False by default)
users.drop_duplicates(keep='first').shape

users.drop_duplicates(keep='last').shape

users.drop_duplicates(keep=False).shape

"""Documentation for [**`drop_duplicates`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop_duplicates.html)"""

# only consider a subset of columns when identifying duplicates
users.duplicated(subset=['age', 'zip_code']).sum()

users.drop_duplicates(subset=['age', 'zip_code']).shape

"""## How do I avoid a SettingWithCopyWarning in pandas?"""

# read a dataset of top-rated IMDb movies into a DataFrame
movies = pd.read_csv('http://bit.ly/imdbratings')
movies.head()

# count the missing values in the 'content_rating' Series
movies.content_rating.isnull().sum()

# examine the DataFrame rows that contain those missing values
movies[movies.content_rating.isnull()]

# examine the unique values in the 'content_rating' Series
movies.content_rating.value_counts()

"""**Goal:** Mark the 'NOT RATED' values as missing values, represented by 'NaN'."""

# first, locate the relevant rows
movies[movies.content_rating=='NOT RATED'].head()

# then, select the 'content_rating' Series from those rows
movies[movies.content_rating=='NOT RATED'].content_rating.head()

# finally, replace the 'NOT RATED' values with 'NaN' (imported from NumPy)
import numpy as np
movies[movies.content_rating=='NOT RATED'].content_rating = np.nan

"""**Problem:** That statement involves two operations, a **`__getitem__`** and a **`__setitem__`**. pandas can't guarantee whether the **`__getitem__`** operation returns a view or a copy of the data.

- If **`__getitem__`** returns a view of the data, **`__setitem__`** will affect the 'movies' DataFrame.
- But if **`__getitem__`** returns a copy of the data, **`__setitem__`** will not affect the 'movies' DataFrame.
"""

# the 'content_rating' Series has not changed
movies.content_rating.isnull().sum()

"""**Solution:** Use the **`loc`** method, which replaces the 'NOT RATED' values in a single **`__setitem__`** operation."""

# replace the 'NOT RATED' values with 'NaN' (does not cause a SettingWithCopyWarning)
movies.loc[movies.content_rating=='NOT RATED', 'content_rating'] = np.nan

# this time, the 'content_rating' Series has changed
movies.content_rating.isnull().sum()

"""**Summary:** Use the **`loc`** method any time you are selecting rows and columns in the same statement.

**More information:** [Modern Pandas (Part 1)](http://tomaugspurger.github.io/modern-1.html)
"""

# create a DataFrame only containing movies with a high 'star_rating'
top_movies = movies.loc[movies.star_rating >= 9, :]
top_movies

"""**Goal:** Fix the 'duration' for 'The Shawshank Redemption'."""

# overwrite the relevant cell with the correct duration
top_movies.loc[0, 'duration'] = 150

"""**Problem:** pandas isn't sure whether 'top_movies' is a view or a copy of 'movies'."""

# 'top_movies' DataFrame has been updated
top_movies

# 'movies' DataFrame has not been updated
movies.head(1)

"""**Solution:** Any time you are attempting to create a DataFrame copy, use the [**`copy`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.copy.html) method."""

# explicitly create a copy of 'movies'
top_movies = movies.loc[movies.star_rating >= 9, :].copy()

# pandas now knows that you are updating a copy instead of a view (does not cause a SettingWithCopyWarning)
top_movies.loc[0, 'duration'] = 150

# 'top_movies' DataFrame has been updated
top_movies

"""Documentation on indexing and selection: [Returning a view versus a copy](http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy)

Stack Overflow: [What is the point of views in pandas if it is undefined whether an indexing operation returns a view or a copy?](http://stackoverflow.com/questions/34884536/what-is-the-point-of-views-in-pandas-if-it-is-undefined-whether-an-indexing-oper)

##  How do I change display options in pandas?
"""

# read a dataset of alcohol consumption into a DataFrame
drinks = pd.read_csv('http://bit.ly/drinksbycountry')

# only 60 rows will be displayed when printing
drinks

# check the current setting for the 'max_rows' option
pd.get_option('display.max_rows')

"""Documentation for [**`get_option`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_option.html)"""

# overwrite the current setting so that all rows will be displayed
pd.set_option('display.max_rows', None)
drinks

# reset the 'max_rows' option to its default
pd.reset_option('display.max_rows')

"""Documentation for [**`set_option`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.set_option.html) and [**`reset_option`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.reset_option.html)"""

# the 'max_columns' option is similar to 'max_rows'
pd.get_option('display.max_columns')

# read the training dataset from Kaggle's Titanic competition into a DataFrame
train = pd.read_csv('http://bit.ly/kaggletrain')
train.head()

# an ellipsis is displayed in the 'Name' cell of row 1 because of the 'max_colwidth' option
pd.get_option('display.max_colwidth')

# overwrite the current setting so that more characters will be displayed
pd.set_option('display.max_colwidth', 1000)
train.head()

# overwrite the 'precision' setting to display 2 digits after the decimal point of 'Fare'
pd.set_option('display.precision', 2)
train.head()

# add two meaningless columns to the drinks DataFrame
drinks['x'] = drinks.wine_servings * 1000
drinks['y'] = drinks.total_litres_of_pure_alcohol * 1000
drinks.head()

# use a Python format string to specify a comma as the thousands separator
pd.set_option('display.float_format', '{:,}'.format)
drinks.head()

# 'y' was affected (but not 'x') because the 'float_format' option only affects floats (not ints)
drinks.dtypes

# view the option descriptions (including the default and current values)
pd.describe_option()

# search for specific options by name
pd.describe_option('rows')

"""Documentation for [**`describe_option`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.describe_option.html)"""

# reset all of the options to their default values
pd.reset_option('all')

"""## How do I create a pandas DataFrame from another object?"""

# create a DataFrame from a dictionary (keys become column names, values become data)
pd.DataFrame({'id':[100, 101, 102], 'color':['red', 'blue', 'red']})

# optionally specify the order of columns and define the index
df = pd.DataFrame({'id':[100, 101, 102], 'color':['red', 'blue', 'red']}, columns=['id', 'color'], index=['a', 'b', 'c'])
df

"""Documentation for [**`DataFrame`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)"""

# create a DataFrame from a list of lists (each inner list becomes a row)
pd.DataFrame([[100, 'red'], [101, 'blue'], [102, 'red']], columns=['id', 'color'])

# create a NumPy array (with shape 4 by 2) and fill it with random numbers between 0 and 1
import numpy as np
arr = np.random.rand(4, 2)
arr

# create a DataFrame from the NumPy array
pd.DataFrame(arr, columns=['one', 'two'])

# create a DataFrame of student IDs (100 through 109) and test scores (random integers between 60 and 100)
pd.DataFrame({'student':np.arange(100, 110, 1), 'test':np.random.randint(60, 101, 10)})

"""Documentation for [**`np.arange`**](http://docs.scipy.org/doc/numpy/reference/generated/numpy.arange.html) and [**`np.random`**](http://docs.scipy.org/doc/numpy/reference/routines.random.html)"""

# 'set_index' can be chained with the DataFrame constructor to select an index
pd.DataFrame({'student':np.arange(100, 110, 1), 'test':np.random.randint(60, 101, 10)}).set_index('student')

"""Documentation for [**`set_index`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.set_index.html)"""

# create a new Series using the Series constructor
s = pd.Series(['round', 'square'], index=['c', 'b'], name='shape')
s

"""Documentation for [**`Series`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html)"""

# concatenate the DataFrame and the Series (use axis=1 to concatenate columns)
pd.concat([df, s], axis=1)

"""**Notes:**

- The Series name became the column name in the DataFrame.
- The Series data was aligned to the DataFrame by its index.
- The 'shape' for row 'a' was marked as a missing value (NaN) because that index was not present in the Series.

Documentation for [**`concat`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html)

## How do I apply a function to a pandas Series or DataFrame?
"""

# read the training dataset from Kaggle's Titanic competition into a DataFrame
train = pd.read_csv('http://bit.ly/kaggletrain')
train.head()

"""**Goal:** Map the existing values of a Series to a different set of values

**Method:** [**`map`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.map.html) (Series method)
"""

# map 'female' to 0 and 'male' to 1
train['Sex_num'] = train.Sex.map({'female':0, 'male':1})
train.loc[0:4, ['Sex', 'Sex_num']]

"""**Goal:** Apply a function to each element in a Series

**Method:** [**`apply`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.apply.html) (Series method)

**Note:** **`map`** can be substituted for **`apply`** in many cases, but **`apply`** is more flexible and thus is recommended
"""

# calculate the length of each string in the 'Name' Series
train['Name_length'] = train.Name.apply(len)
train.loc[0:4, ['Name', 'Name_length']]

# round up each element in the 'Fare' Series to the next integer
import numpy as np
train['Fare_ceil'] = train.Fare.apply(np.ceil)
train.loc[0:4, ['Fare', 'Fare_ceil']]

# we want to extract the last name of each person
train.Name.head()

# use a string method to split the 'Name' Series at commas (returns a Series of lists)
train.Name.str.split(',').head()

# define a function that returns an element from a list based on position
def get_element(my_list, position):
    return my_list[position]

# apply the 'get_element' function and pass 'position' as a keyword argument
train.Name.str.split(',').apply(get_element, position=0).head()

# alternatively, use a lambda function
train.Name.str.split(',').apply(lambda x: x[0]).head()

"""**Goal:** Apply a function along either axis of a DataFrame

**Method:** [**`apply`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html) (DataFrame method)
"""

# read a dataset of alcohol consumption into a DataFrame
drinks = pd.read_csv('http://bit.ly/drinksbycountry')
drinks.head()

# select a subset of the DataFrame to work with
drinks.loc[:, 'beer_servings':'wine_servings'].head()

# apply the 'max' function along axis 0 to calculate the maximum value in each column
drinks.loc[:, 'beer_servings':'wine_servings'].apply(max, axis=0)

# apply the 'max' function along axis 1 to calculate the maximum value in each row
drinks.loc[:, 'beer_servings':'wine_servings'].apply(max, axis=1).head()

# use 'np.argmax' to calculate which column has the maximum value for each row
drinks.loc[:, 'beer_servings':'wine_servings'].apply(np.argmax, axis=1).head()

"""**Goal:** Apply a function to every element in a DataFrame

**Method:** [**`applymap`**](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.applymap.html) (DataFrame method)
"""

# convert every DataFrame element into a float
drinks.loc[:, 'beer_servings':'wine_servings'].applymap(float).head()

# overwrite the existing DataFrame columns
drinks.loc[:, 'beer_servings':'wine_servings'] = drinks.loc[:, 'beer_servings':'wine_servings'].applymap(float)
drinks.head()

